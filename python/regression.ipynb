{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from google.protobuf.internal.decoder import _DecodeVarint32\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from proto.py.marginal_state_pb2 import MarginalState\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize true parameters\n",
    "dim = 3\n",
    "betas = [np.array(dim*[-3]), np.array(dim*[+0]), np.array(dim*[+3])]\n",
    "sigma2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to save files with Unix-like newlines\n",
    "def save_np(filename, npobj):\n",
    "    with open(filename, 'wb') as f:\n",
    "        np.savetxt(f, npobj, fmt='%1.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "rng = 20201124\n",
    "np.random.seed(rng)\n",
    "n = 100\n",
    "xx = np.random.normal(loc=0.0, scale=1.0, size=(n, dim))\n",
    "# cc = np.random.randint(low=0, high=3, size=n)\n",
    "cc = int(n/3)*[0] + int(n/3)*[1] + (n - 2*int(n/3))*[2]\n",
    "yy = np.zeros(n)\n",
    "for i in range(n):\n",
    "    mu = np.dot(xx[i, :], betas[cc[i]])\n",
    "    y = np.random.normal(loc=mu, scale=sigma2)\n",
    "    yy[i] = y\n",
    "# Save to file\n",
    "save_np(\"../resources/csv/in/covs_lru.csv\", xx)\n",
    "save_np(\"../resources/csv/in/data_lru.csv\", yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate grid points (not needed in the notebook)\n",
    "np.random.seed(rng)\n",
    "yy_grid = np.arange(-5.0, +5.0, 0.1)\n",
    "xx_grid = np.random.normal(loc=0.0, scale=1.0, size=(yy_grid.size, dim))\n",
    "# Save to file\n",
    "save_np(\"../resources/csv/in/covs_grid_lru.csv\", xx_grid)\n",
    "save_np(\"../resources/csv/in/grid_lru.csv\", yy_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the executable\n",
    "cmd = [\"../build/run\",\n",
    "    \"Neal2\", str(rng), \"0\", \"1000\", \"100\",\n",
    "    \"LinRegUni\", \"../resources/asciipb/lin_reg_uni_fixed.asciipb\",\n",
    "    \"DP\", \"../resources/asciipb/dp_gamma_prior.asciipb\",\n",
    "    \"../lru.recordio\",\n",
    "    \"../resources/csv/in/data_lru.csv\",  \"../resources/csv/in/covs_grid_lru.csv\",\n",
    "    \"../resources/csv/out/lru_dens.csv\", \"../resources/csv/out/lru_mass.csv\",\n",
    "    \"../resources/csv/out/lru_nclu.csv\", \"../resources/csv/out/lru_clus.csv\",\n",
    "    \"../resources/csv/in/covs_lru.csv\",  \"../resources/csv/in/covs_grid_lru.csv\"\n",
    "]\n",
    "subprocess.run(cmd, capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to read file collector, courtesy of\n",
    "# github.com/mberaha/utils/blob/master/proto_utils/py/recordio.py\n",
    "def readManyFromFile(filename, msgType):\n",
    "    out = []\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        buf = fp.read()\n",
    "    n = 0\n",
    "    while n < len(buf):\n",
    "        msg_len, new_pos = _DecodeVarint32(buf, n)\n",
    "        n = new_pos\n",
    "        msg_buf = buf[n:n+msg_len]\n",
    "        try:\n",
    "            msg = msgType()\n",
    "            msg.ParseFromString(msg_buf)\n",
    "            out.append(msg)\n",
    "            n += msg_len\n",
    "        except Exception as e:\n",
    "            break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read chain\n",
    "chain = readManyFromFile('../lru.recordio', MarginalState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare original betas and regression betas of some iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_print = []\n",
    "for i in (0, 2, 1):\n",
    "    betas_print.append([\"%1.1f\"%float(b) for b in betas[i]])\n",
    "\n",
    "print(\"Original betas:\")\n",
    "print(betas_print)\n",
    "\n",
    "print(\"Chain betas of iterations with 3 clusters:\")\n",
    "for state in chain:\n",
    "    if len(state.cluster_states) == 3:\n",
    "        betas_chain = []\n",
    "        for clus in state.cluster_states:\n",
    "            beta = clus.lin_reg_univ_ls_state.regression_coeffs.data\n",
    "            betas_chain.append([\"%1.1f\"%b for b in beta])\n",
    "        print(betas_chain, f\"(iteration n. {state.iteration_num})\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare true and posterior clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read posterior clustering\n",
    "cc_post = np.loadtxt('../resources/csv/out/lru_clus.csv')\n",
    "cc_post = [int(_) for _ in cc_post]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [i for i in range(n)]\n",
    "\n",
    "size_true = len(set(cc))\n",
    "cmap1 = plt.cm.get_cmap('hsv', size_true+1)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,5))\n",
    "for i in idxs:\n",
    "    ax1.scatter(i, i, color=cmap1(cc[i]))\n",
    "ax1.set_title(f\"True clustering, with {size_true} clusters\")\n",
    "\n",
    "size_post = len(set(cc_post))\n",
    "cmap2 = plt.cm.get_cmap('hsv', size_post+1)\n",
    "for i in idxs:\n",
    "    ax2.scatter(i, i, color=cmap2(cc_post[i]))\n",
    "ax2.set_title(f\"Posterior clustering, with {size_post} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vs regular linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE of a regular linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(xx, yy)\n",
    "mse_sk = mean_squared_error(yy, model.predict(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted values of the model\n",
    "yyhat = []\n",
    "## Loop over data\n",
    "for i in range(n):\n",
    "    yhat = 0.0\n",
    "    ## Loop over iterations\n",
    "    for j in range(len(chain)):\n",
    "        alloc = chain[j].cluster_allocs[i]\n",
    "        clus = chain[j].cluster_states[alloc]\n",
    "        beta_ij = clus.lin_reg_univ_ls_state.regression_coeffs.data\n",
    "        ## Prediction for the single iteration\n",
    "        yhat += np.dot(beta_ij, xx[i])\n",
    "    ## Compute mean of predictions across all iterations\n",
    "    yyhat.append(yhat / len(chain))\n",
    "\n",
    "# Display data alongside predicted values\n",
    "# print(np.column_stack((yy, yyhat)))\n",
    "\n",
    "# Compute MSE of the model\n",
    "mse_lddp = np.sum((yy-yyhat)**2) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two MSEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regular model:\", mse_sk)\n",
    "print(\"LDDP model   :\", mse_lddp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
