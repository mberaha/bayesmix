{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the three algorithms by Neal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from google.protobuf.internal.decoder import _DecodeVarint32\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from proto.py.marginal_state_pb2 import MarginalState\n",
    "import arviz as az\n",
    "# import pip\n",
    "# pip.main([\"install\", \"arviz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to save files with Unix-like newlines\n",
    "def save_np(filename, npobj):\n",
    "    with open(filename, 'wb') as f:\n",
    "        np.savetxt(f, npobj, fmt='%1.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "rng = 20201124\n",
    "np.random.seed(rng)\n",
    "n = 200\n",
    "mean1 = -3.0\n",
    "mean2 = +3.0\n",
    "norm1 = np.random.normal(loc=mean1, scale=1.0, size=int(n/2))\n",
    "norm2 = np.random.normal(loc=mean2, scale=1.0, size=int(n/2))\n",
    "data_uni = np.concatenate((norm1, norm2))\n",
    "# Generate grid\n",
    "grid_uni = np.arange(-10, +10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "save_np(\"../resources/csv/in/data_uni.csv\", data_uni)\n",
    "save_np(\"../resources/csv/in/grid_uni.csv\", grid_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True density of data\n",
    "true_pdf = 0.5 * stats.norm.pdf(grid_uni, mean1, 1.0) + \\\n",
    "           0.5 * stats.norm.pdf(grid_uni, mean2, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of algorithms\n",
    "algos = [\"Neal2\", \"Neal3\", \"Neal8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the executable\n",
    "for algo in algos:\n",
    "    cmd = [\"../build/run\",\n",
    "        algo, str(rng), \"0\", \"1000\", \"100\",\n",
    "        \"NNIG\", \"../resources/asciipb/nnig_ngg_prior.asciipb\",\n",
    "        \"DP\",   \"../resources/asciipb/dp_gamma_prior.asciipb\",\n",
    "        f\"../{algo}.recordio\",\n",
    "        \"../resources/csv/in/data_uni.csv\",\n",
    "        \"../resources/csv/in/grid_uni.csv\",\n",
    "        f\"../resources/csv/out/uni_{algo}_dens.csv\",\n",
    "        f\"../resources/csv/out/uni_{algo}_mass.csv\",\n",
    "        f\"../resources/csv/out/uni_{algo}_nclu.csv\",\n",
    "        f\"../resources/csv/out/uni_{algo}_clus.csv\"\n",
    "    ]\n",
    "    subprocess.run(cmd, capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read clusterings\n",
    "clusterings = dict.fromkeys(algos)\n",
    "for algo in algos:\n",
    "    clusterings[algo] = np.loadtxt(f\"../resources/csv/out/uni_{algo}_clus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clusterings\n",
    "print(np.linalg.norm(clusterings[\"Neal2\"]-clusterings[\"Neal3\"], 1))\n",
    "print(np.linalg.norm(clusterings[\"Neal2\"]-clusterings[\"Neal8\"], 1))\n",
    "print(np.linalg.norm(clusterings[\"Neal3\"]-clusterings[\"Neal8\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densities\n",
    "plt.figure(figsize=(16, 8))\n",
    "for algo in algos:\n",
    "    matr = np.genfromtxt(f\"../resources/csv/out/uni_{algo}_dens.csv\", delimiter=',')\n",
    "    plt.plot(grid_uni, np.exp(np.mean(matr, axis=0)))\n",
    "plt.plot(grid_uni, true_pdf, color=\"red\", linestyle=\"--\")\n",
    "plt.legend(algos + [\"true\"])\n",
    "plt.title(\"Univariate densities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to read file collector, courtesy of\n",
    "# github.com/mberaha/utils/blob/master/proto_utils/py/recordio.py\n",
    "def readManyFromFile(filename, msgType):\n",
    "    out = []\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        buf = fp.read()\n",
    "    n = 0\n",
    "    while n < len(buf):\n",
    "        msg_len, new_pos = _DecodeVarint32(buf, n)\n",
    "        n = new_pos\n",
    "        msg_buf = buf[n:n+msg_len]\n",
    "        try:\n",
    "            msg = msgType()\n",
    "            msg.ParseFromString(msg_buf)\n",
    "            out.append(msg)\n",
    "            n += msg_len\n",
    "        except Exception as e:\n",
    "            break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Effective Sample Sizes for each algorithm\n",
    "ESS = dict.fromkeys(algos)\n",
    "for algo in algos:\n",
    "    # Read chain\n",
    "    chain = readManyFromFile(f\"../{algo}.recordio\", MarginalState)\n",
    "    # Record number of clusters at each iteration\n",
    "    n_clusters = np.empty(len(chain))\n",
    "    for i in range(len(chain)):\n",
    "        state = chain[i]\n",
    "        n_clusters[i] = len(state.cluster_states)\n",
    "    ESS[algo] = az.ess(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times of MCMC, collected via the progressbar\n",
    "filecoll_times = dict(zip(algos, [5.690, 6.824, 8.636]))\n",
    "memocoll_times = dict(zip(algos, [5.617, 6.040, 7.348]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display computed ESS\n",
    "for key, val in ESS.items():\n",
    "    print(key, \"ESS =\", val, \"-> ESS/time =\", val/filecoll_times[key], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
